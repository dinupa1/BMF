{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8519371-4e98-4118-8d89-b2c82126e499",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h5py\n",
    "\n",
    "import uproot\n",
    "import awkward as ak"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94148149-23bc-4e32-85c0-667e030712ba",
   "metadata": {},
   "source": [
    "# E906 Messy MC Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe69e0b-a82a-454e-a4c8-88614f4391cb",
   "metadata": {},
   "source": [
    "Let $\\beta_{0}$ and $\\beta_{1}$ define two distributions, $p(x|\\beta_{0})$ and $p(x|\\beta_{1})$ respectively. Then the likelihood ratio is defined by;\n",
    "$$\n",
    "\\mathcal{L}(x| \\beta_{0}, \\beta_{1}) =  \\frac{p(x|\\beta_{0})}{p(x|\\beta_{1})}\n",
    "$$\n",
    "\n",
    "A classifier function $f$, designed to distinguish samples drawn from $p(x|\\beta_{0})$ and $p(x|\\beta_{1})$, can be used to approximate likelihood ratios;\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x| \\beta_{0}, \\beta_{1}) =  \\frac{f(x, \\beta_{0}, \\beta_{1})}{1 - f(x, \\beta_{0}, \\beta_{1})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323da59-6e4a-4a84-9c80-da4b58bd197c",
   "metadata": {},
   "source": [
    "Consider the cross-section of the Drell-Yan (DY) angular distribution;\n",
    "\n",
    "$$\n",
    "\\frac{d\\sigma}{d\\Omega} \\propto 1 + \\lambda \\cos^{2}\\theta + \\mu\\sin2\\theta\\cos\\phi + \\frac{\\nu}{2}\\sin^{2}\\theta\\cos2\\phi\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3d5efe-412e-4c6d-a306-80d443a58623",
   "metadata": {},
   "source": [
    "Our goal is to extract Drell-Yan (DY) angular coefficients, $\\lambda$, $\\mu$, and $\\nu$, using the likelihood ratio method. We aim to train a classifier (neural network) capable of classifying two samples. We sample $\\lambda$, $\\mu$, and $\\nu$ from uniform ranges: $\\lambda$ in $[-1, 1]$, $\\mu$ and $\\nu$ in $[-0.5, 0.5]$. We extract the bin center and bin content of $\\phi$ vs. $\\cos\\theta$ histograms as inputs and weights in the classifier and loss function. The two classes are defined as follows:\n",
    "\n",
    "```\n",
    "H0: (lambda=0, mu=0, nu=0, phi, costheta) with beta = (lambda, mu, nu) --> label = 0\n",
    "H1: (lambda, mu, nu, phi, costheta) with beta = (lambda, mu, nu) --> label = 1\n",
    "```\n",
    "\n",
    "Note that the class with label 0 has mismatching $\\beta$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61b70e0d-3fdf-480d-b347-5d43d1b994bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_train = uproot.open(\"net.root:X0_train_tree\")\n",
    "X1_train = uproot.open(\"net.root:X1_train_tree\")\n",
    "X0_test = uproot.open(\"net.root:X0_test_tree\")\n",
    "X1_test = uproot.open(\"net.root:X1_test_tree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "596875ea-d58b-493f-988b-328d47dc1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = h5py.File(\"net.hdf5\", \"w\")\n",
    "\n",
    "outputs.create_dataset(\"X0_train/thetas\", data=X0_train[\"thetas\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_train/X_par\", data=X0_train[\"X_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_train/X_det\", data=X0_train[\"X_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_train/W_par\", data=X0_train[\"W_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_train/W_det\", data=X0_train[\"W_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_train/label\", data=X0_train[\"label\"].array().to_numpy())\n",
    "\n",
    "outputs.create_dataset(\"X1_train/thetas\", data=X1_train[\"thetas\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_train/X_par\", data=X1_train[\"X_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_train/X_det\", data=X1_train[\"X_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_train/W_par\", data=X1_train[\"W_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_train/W_det\", data=X1_train[\"W_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_train/label\", data=X1_train[\"label\"].array().to_numpy())\n",
    "\n",
    "outputs.create_dataset(\"X0_test/thetas\", data=X0_test[\"thetas\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_test/X_par\", data=X0_test[\"X_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_test/X_det\", data=X0_test[\"X_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_test/W_par\", data=X0_test[\"W_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_test/W_det\", data=X0_test[\"W_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X0_test/label\", data=X0_test[\"label\"].array().to_numpy())\n",
    "\n",
    "outputs.create_dataset(\"X1_test/thetas\", data=X1_test[\"thetas\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_test/X_par\", data=X1_test[\"X_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_test/X_det\", data=X1_test[\"X_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_test/W_par\", data=X1_test[\"W_par\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_test/W_det\", data=X1_test[\"W_det\"].array().to_numpy())\n",
    "outputs.create_dataset(\"X1_test/label\", data=X1_test[\"label\"].array().to_numpy())\n",
    "\n",
    "outputs.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
