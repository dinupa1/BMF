{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1461a6d-6f96-46d7-9fe4-f901f8361609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72773ec-6cf0-4308-a900-7f013e23b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    }
   ],
   "source": [
    "# use cuda\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using device {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec22ccff-1f7c-4630-ba32-70327337e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate weights analytically\n",
    "\n",
    "def cal_weight(xx1, xx2, xx3, phi, costh):\n",
    "    weight = 1. + xx1* costh* costh + 2.* xx2* costh* torch.sqrt(1. - costh* costh)* torch.cos(phi) + 0.5* xx3* (1. - costh* costh)* torch.cos(2.* phi)\n",
    "    return weight/(1. + costh* costh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "371a5750-c51e-41d1-9e16-8924c6036efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_features=2, out_features=1):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, 32, bias=True)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 32, bias=True)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, out_features, bias=True)\n",
    "        self.act3 = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.fc1(x))\n",
    "        x = self.act2(self.fc2(x))\n",
    "        x = self.act3(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ceaf37-feca-47de-89a6-483f1067bb18",
   "metadata": {},
   "source": [
    "# Extracting Angular Coefficients using SRGN Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5ccba7-465e-46dd-ad3e-c4831cc74e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "data = np.load(\"test_mc.npy\")\n",
    "theta0, theta1 = train_test_split(data, test_size=0.5, shuffle=True)\n",
    "\n",
    "theta0 = torch.Tensor(theta0)\n",
    "theta1 = torch.Tensor(theta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd187163-5d92-4ee9-a237-ea9b04661912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total trainable params: 1185\n"
     ]
    }
   ],
   "source": [
    "net = Net().to(device)\n",
    "total_trainable_params = sum(p.numel() for p in net.parameters())\n",
    "print('total trainable params:', total_trainable_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76743c19-a474-4b8f-88ba-c7cf8f24d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown parameters\n",
    "\n",
    "LAMBDA_0, MU_0, NU_0 = 0.4, 0.0, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26d4719-bfb5-4358-955d-181929353ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 1024\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728a7793-38cb-42db-9eb1-9a49e57ef725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run classifier\n",
    "# true_{mass, pT, xF, phi, costh} and reco_{mass, pT, xF, phi, costh}\n",
    "\n",
    "def run_classifier(x1, x2, x3, fit_type='generator'):\n",
    "    \n",
    "    if fit_type == 'generator':\n",
    "        theta0_G = theta0[:, 3:5]\n",
    "        weight0_G = cal_weight(LAMBDA_0, MU_0, NU_0, theta0[:, 3], theta0[:, 4]).reshape(-1, 1)\n",
    "        label0_G = torch.zeros(theta0_G.shape[0], dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        theta1_G = theta1[:, 3:5]\n",
    "        weight1_G = cal_weight(x1, x2, x3, theta1[:, 3], theta1[:, 4]).reshape(-1, 1)\n",
    "        label1_G = torch.ones(theta1_G.shape[0], dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        theta = torch.cat((theta0_G, theta1_G), 0)\n",
    "        weight = torch.cat((weight0_G, weight1_G), 0)\n",
    "        label = torch.cat((label0_G, label1_G), 0)\n",
    "        \n",
    "        # print(\"min: {}, max: {}\".format(torch.min(weight1_G), torch.max(weight1_G)))\n",
    "        \n",
    "    elif fit_type == 'detector':\n",
    "        theta0_S = theta0[:, 8:]\n",
    "        weight0_S = cal_weight(LAMBDA_0, MU_0, NU_0, theta0[:, 3], theta0[:, 4]).reshape(-1, 1)\n",
    "        label0_S = torch.zeros(theta0_S.shape[0], dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        theta1_S = theta1[:, 8:]\n",
    "        weight1_S = cal_weight(x1, x2, x3, theta1[:, 3], theta1[:, 4]).reshape(-1, 1)\n",
    "        label1_S = torch.ones(theta1_S.shape[0], dtype=torch.float32).reshape(-1, 1)\n",
    "        \n",
    "        theta = torch.cat((theta0_S, theta1_S), 0)\n",
    "        weight = torch.cat((weight0_S, weight1_S), 0)\n",
    "        label = torch.cat((label0_S, label1_S), 0)\n",
    "        \n",
    "        # print(\"min: {}, max: {}\".format(torch.min(weight1_S), torch.max(weight1_S)))\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"fit type must be set to 'generator' or 'detector'\")\n",
    "        \n",
    "    dataset = TensorDataset(theta.to(device), weight.to(device), label.to(device))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    loss = []\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        run_loss, m = 0., 0.\n",
    "        for inputs, weights, targets in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            criterion.weight = weights\n",
    "            loss_batch = criterion(outputs, targets)\n",
    "            \n",
    "            loss_batch.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            run_loss += loss_batch.item()\n",
    "            m += 1.0\n",
    "            \n",
    "        loss.append(run_loss / m)\n",
    "        # print(\"epoch : {} loss : {}\".format(epoch + 1, run_loss / m))\n",
    "        \n",
    "    # plt.figure(figsize=(6, 5))\n",
    "    # plt.plot(loss)\n",
    "    # plt.xlabel(\"epoch\")\n",
    "    # plt.ylabel(\"loss\")\n",
    "    # # plt.savefig(\"../imgs/loss.png\")\n",
    "    # # plt.close(\"all\")\n",
    "    # plt.show()\n",
    "    \n",
    "    net.eval()\n",
    "    outputs = net(theta.to(device)).cpu().detach().numpy()\n",
    "    auc = roc_auc_score(label, outputs, sample_weight=weight)\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24118df7-238e-4ad1-a9ed-64e40b4d145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use minimizer to extract parameters\n",
    "\n",
    "def get_AUC_G(x):\n",
    "    AUC_G = run_classifier(x[0], x[1], x[2], \"generator\")\n",
    "    return AUC_G\n",
    "\n",
    "\n",
    "def get_AUC_S(x):\n",
    "    AUC_S = run_classifier(x[0], x[1], x[2], \"detector\")\n",
    "    return AUC_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fdf2a1e-ca46-42dc-861e-9aeec38b6e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict optimization to bounds of parameterization of the reweighting function\n",
    "mybounds = Bounds(np.array([0.1, -0.3, -0.1]), np.array([0.7, 0.3, 0.5]))\n",
    "\n",
    "LAMBDA_G = []\n",
    "MU_G = []\n",
    "NU_G = []\n",
    "FUNC_G = []\n",
    "LAMBDA_S = []\n",
    "MU_S = []\n",
    "NU_S = []\n",
    "FUNC_S = []\n",
    "\n",
    "\n",
    "def run_minimizer():\n",
    "    for i in range(2):\n",
    "        lambda_prime = np.random.uniform(0.1, 0.7, 1)\n",
    "        mu_prime = np.random.uniform(-0.3, 0.3, 1)\n",
    "        nu_prime = np.random.uniform(-0.1, 0.5, 1)\n",
    "        theta_prime = np.array([lambda_prime[0], mu_prime[0], nu_prime[0]])\n",
    "        print(\"iteration : {} theta prime = ({:.2f}, {:.2f}, {:.2f})\".format(i+1, theta_prime[0], theta_prime[1], theta_prime[2]))\n",
    "        res = minimize(get_AUC_G, theta_prime, method=\"Powell\", bounds=mybounds, options={\n",
    "                                                                            'maxiter': 100,\n",
    "                                                                            'disp': True,\n",
    "                                                                            'return_all': True\n",
    "                                                                            })\n",
    "        \n",
    "        LAMBDA_G.append(res[\"x\"][0])\n",
    "        MU_G.append(res[\"x\"][1])\n",
    "        NU_G.append(res[\"x\"][2])\n",
    "        FUNC_G.append(res[\"fun\"])\n",
    "        \n",
    "        print(\"best theta : ({:.2f}, {:.2f}, {:.2f})\".format(res[\"x\"][0], res[\"x\"][1], res[\"x\"][2]))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        res = minimize(get_AUC_S, theta_prime, method=\"Powell\", bounds=mybounds, options={\n",
    "                                                                            'maxiter': 100,\n",
    "                                                                            'disp': True,\n",
    "                                                                            'return_all': True\n",
    "                                                                            })\n",
    "        \n",
    "        LAMBDA_S.append(res[\"x\"][0])\n",
    "        MU_S.append(res[\"x\"][1])\n",
    "        NU_S.append(res[\"x\"][2])\n",
    "        FUNC_S.append(res[\"fun\"])\n",
    "        \n",
    "        print(\"best theta : ({:.2f}, {:.2f}, {:.2f})\".format(res[\"x\"][0], res[\"x\"][1], res[\"x\"][2]))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7f8692-e879-4fe5-8543-5802da45cdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_minimizer()\n",
    "\n",
    "print(\"best fit generator level = {:.2f} +/- {:.2f}\".format(np.mean(LAMBDA_G), np.std(LAMBDA_G)))\n",
    "print(\"best fit generator level = {:.2f} +/- {:.2f}\".format(np.mean(MU_G), np.std(MU_G)))\n",
    "print(\"best fit generator level = {:.2f} +/- {:.2f}\".format(np.mean(NU_G), np.std(NU_G)))\n",
    "print(\"best fit detector level = {:.2f} +/- {:.2f}\".format(np.mean(LAMBDA_S), np.std(LAMBDA_S)))\n",
    "print(\"best fit generator level = {:.2f} +/- {:.2f}\".format(np.mean(MU_S), np.std(MU_S)))\n",
    "print(\"best fit generator level = {:.2f} +/- {:.2f}\".format(np.mean(NU_S), np.std(NU_S)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
